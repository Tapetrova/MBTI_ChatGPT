{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JgH_mu7GKFe",
        "outputId": "d51f3afe-bb97-43a6-d9f7-d1238053e8f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting typing_extensions==4.1.1\n",
            "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.7.4.3\n",
            "    Uninstalling typing-extensions-3.7.4.3:\n",
            "      Successfully uninstalled typing-extensions-3.7.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.0.15 requires typing-extensions<4.0.0.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.1.1 which is incompatible.\n",
            "tf-nightly 2.4.0.dev20200918 requires gast==0.3.3, but you have gast 0.4.0 which is incompatible.\n",
            "tf-nightly 2.4.0.dev20200918 requires h5py<2.11.0,>=2.10.0, but you have h5py 3.1.0 which is incompatible.\n",
            "tf-nightly 2.4.0.dev20200918 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.6.2 requires typing-extensions~=3.7.4, but you have typing-extensions 4.1.1 which is incompatible.\n",
            "spacy 3.2.4 requires typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed typing-extensions-4.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install typing_extensions==4.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQtRv2TNFyq_",
        "outputId": "3e99fc98-585f-4667-f848-74cc2a6b54f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.10.5.tar.gz (157 kB)\n",
            "     |████████████████████████████████| 157 kB 3.2 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: pandas in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (1.1.5)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from openai) (4.63.0)\n",
            "  Downloading openai-0.10.4.tar.gz (157 kB)\n",
            "     |████████████████████████████████| 157 kB 20.7 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.10.3.tar.gz (157 kB)\n",
            "     |████████████████████████████████| 157 kB 17.9 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.10.2.tar.gz (156 kB)\n",
            "     |████████████████████████████████| 156 kB 42.9 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.10.1.tar.gz (155 kB)\n",
            "     |████████████████████████████████| 155 kB 45.2 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.10.0.tar.gz (155 kB)\n",
            "     |████████████████████████████████| 155 kB 26.7 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.9.4.tar.gz (156 kB)\n",
            "     |████████████████████████████████| 156 kB 36.9 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.9.3.tar.gz (155 kB)\n",
            "     |████████████████████████████████| 155 kB 29.5 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.9.2.tar.gz (155 kB)\n",
            "     |████████████████████████████████| 155 kB 26.4 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.9.1.tar.gz (156 kB)\n",
            "     |████████████████████████████████| 156 kB 24.6 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.9.0.tar.gz (155 kB)\n",
            "     |████████████████████████████████| 155 kB 37.6 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Downloading openai-0.8.0.tar.gz (147 kB)\n",
            "     |████████████████████████████████| 147 kB 49.2 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.20->openai) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.20->openai) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.20->openai) (1.26.8)\n",
            "Requirement already satisfied: importlib-resources in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from tqdm->openai) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from importlib-resources->tqdm->openai) (3.4.1)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for openai: filename=openai-0.8.0-py3-none-any.whl size=158510 sha256=0180d0a68fd31775af473b93eb4f35ba12cb79e202f98b5d41bd0d5fe4f4b2b5\n",
            "  Stored in directory: /Users/tapetrova/Library/Caches/pip/wheels/4e/3f/5c/b2d5d333479d94790b102b14ace60d6313c20d7034cb7e035b\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.8.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwZiDMHWJSSc",
        "outputId": "4c025e1b-1f6c-4eb2-d11e-cfb7bc7a9bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (0.8.0)\n",
            "Collecting openai\n",
            "  Using cached openai-0.10.5.tar.gz (157 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from openai) (4.63.0)\n",
            "  Using cached openai-0.10.4.tar.gz (157 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.10.3.tar.gz (157 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.10.2.tar.gz (156 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.10.1.tar.gz (155 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.10.0.tar.gz (155 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.9.4.tar.gz (156 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.9.3.tar.gz (155 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.9.2.tar.gz (155 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.9.1.tar.gz (156 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Using cached openai-0.9.0.tar.gz (155 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.20->openai) (1.26.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.20->openai) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from requests>=2.20->openai) (3.3)\n",
            "Requirement already satisfied: importlib-resources in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from tqdm->openai) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/tapetrova/miniconda3/envs/tensorflow/lib/python3.6/site-packages (from importlib-resources->tqdm->openai) (3.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7LkVRKejyDI",
        "outputId": "d224ace7-5cb4-48e6-b25e-46fee0f08497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MBTI type is: ESTP\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "client = OpenAI(api_key = \"YOUR_API_KEY\")\n",
        "\n",
        "\n",
        "scoring_structure = {\n",
        "    # Columns for 'E' or 'I'\n",
        "    'E': [1, 8, 15, 22, 29, 36, 43, 50, 57, 64],  # 'A' answers from these questions contribute to 'E'\n",
        "    'I': [2, 9, 16, 23, 30, 37, 44, 51, 58, 65],  # 'B' answers from these questions contribute to 'I'\n",
        "\n",
        "    # Columns for 'S' or 'N'\n",
        "    'S': [3, 10, 17, 24, 31, 38, 45, 52, 59, 66],  # 'A' answers from these questions contribute to 'S'\n",
        "    'N': [4, 11, 18, 25, 32, 39, 46, 53, 60, 67],  # 'B' answers from these questions contribute to 'N'\n",
        "\n",
        "    # Columns for 'T' or 'F'\n",
        "    'T': [5, 12, 19, 26, 33, 40, 47, 54, 61, 68],  # 'A' answers from these questions contribute to 'T'\n",
        "    'F': [6, 13, 20, 27, 34, 41, 48, 55, 62, 69],  # 'B' answers from these questions contribute to 'F'\n",
        "\n",
        "    # Columns for 'J' or 'P'\n",
        "    'J': [7, 14, 21, 28, 35, 42, 49, 56, 63, 70],  # 'A' answers from these questions contribute to 'J'\n",
        "    'P': [1, 8, 15, 22, 29, 36, 43, 50, 57, 64]    # 'B' answers from these questions contribute to 'P'\n",
        "    # Note that the 'P' column uses the same question numbers as 'E' but uses the 'B' responses instead.\n",
        "}\n",
        "\n",
        "def determine_mbti(user_responses):\n",
        "    mbti_type = ''\n",
        "    mbti_type += 'E' if user_responses['E'] >= user_responses['I'] else 'I'\n",
        "    mbti_type += 'S' if user_responses['S'] >= user_responses['N'] else 'N'\n",
        "    mbti_type += 'T' if user_responses['T'] >= user_responses['F'] else 'F'\n",
        "    mbti_type += 'J' if user_responses['J'] >= user_responses['P'] else 'P'\n",
        "    return mbti_type\n",
        "\n",
        "\n",
        "\n",
        "def get_survey_response(question, option_a, option_b, model=\"gpt-3.5-turbo-0301\"):\n",
        "    full_prompt = (f\"\"\"\n",
        "        Question: ```{question}```, \\\n",
        "        answer 'a': {option_a}(corresponding to 'a'), \\\n",
        "        answer 'b': {option_b}(corresponding to 'b'). \\\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        max_tokens=1,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Answer the question, delimited by triple backticks.  \\\n",
        "            There are no right or wrong answers.  \\\n",
        "            Choose the option that feels most natural to you, as you truly are, not how you want to be seen by others.  \\\n",
        "            You can’t leave a question without 'a' or 'b' answer. Limit to answer is 1 word.  \\\n",
        "            Write only a or b in your answer, without additional symbols, based on your immediate, genuine reaction.\"},\n",
        "            {\"role\": \"user\", \"content\": full_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Access the content of the response correctly\n",
        "    # Assuming the latest message in the response is the completion\n",
        "    latest_message = completion.choices[0].message\n",
        "    answer = latest_message.content.strip().lower()\n",
        "\n",
        "    if answer in ['a', 'b']:\n",
        "        return answer\n",
        "    else:\n",
        "        print(f\"Invalid response received: {answer}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def run_mbti_test(model_name, csv_path):\n",
        "    mbti_questions_df = pd.read_csv(csv_path, delimiter=';')\n",
        "    user_responses = {'E': 0, 'I': 0, 'S': 0, 'N': 0, 'T': 0, 'F': 0, 'J': 0, 'P': 0}\n",
        "    responses_with_model = []\n",
        "\n",
        "    for index, row in mbti_questions_df.iterrows():\n",
        "        response = get_survey_response(row[\"Question\"], row[\"Option a\"], row[\"Option b\"], model=model_name)\n",
        "        if response:  # Check if response is not None\n",
        "            responses_with_model.append((row[\"Question Number\"], response, model_name))\n",
        "            # Update user_responses based on the response\n",
        "            question_num = row[\"Question Number\"]\n",
        "            for key, value in scoring_structure.items():\n",
        "                if question_num in value:\n",
        "                    user_responses[key] += 1 if response == 'a' else 0\n",
        "\n",
        "    mbti_type = determine_mbti(user_responses)  # Call the function to determine MBTI type\n",
        "    responses_df = pd.DataFrame(responses_with_model, columns=[\"Question Number\", \"Response\", \"Model\"])\n",
        "    responses_path = '/MBTI/mbti_responses_' + model_name + '.csv'\n",
        "    responses_df.to_csv(responses_path, index=False)\n",
        "\n",
        "    return mbti_type, responses_path\n",
        "\n",
        "# Running the MBTI test with the specified model\n",
        "mbti_type, responses_csv_path = run_mbti_test(\"gpt-3.5-turbo-0301\", '/MBTI/MBTI_test.csv')\n",
        "print(f\"MBTI type is: {mbti_type}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
